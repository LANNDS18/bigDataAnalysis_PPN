{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import geopy.distance\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import struct, udf, col, desc, row_number, min, max, lag\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/24 17:34:26 WARN Utils: Your hostname, ZdeMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.10.0.76 instead (on interface en0)\n",
      "22/01/24 17:34:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/24 17:34:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('spark.sql.warehouse.dir',\n  'file:/Users/zwill/PycharmProjects/bigData_analysis/pyspark_analysis/spark-warehouse'),\n ('spark.rdd.compress', 'True'),\n ('spark.driver.host', '10.10.0.76'),\n ('spark.driver.port', '62335'),\n ('spark.serializer.objectStreamReset', '100'),\n ('spark.master', 'local[*]'),\n ('spark.submit.pyFiles', ''),\n ('spark.executor.id', 'driver'),\n ('spark.submit.deployMode', 'client'),\n ('spark.app.id', 'local-1643045667524'),\n ('spark.ui.showConsoleProgress', 'true'),\n ('spark.app.startTime', '1643045666821'),\n ('spark.app.name', 'pyspark-shell')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext(master=\"local[*]\")\n",
    "spark = SparkSession.builder.appName(\"Assignment 2 Wuwei Zhang\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset = [('A', 2, 1, 70), ('A', 3, 5, 80), ('C', 5, 3, 90), ('C', 5, 4, 100), ('E', 6, 5, 110)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[('C', 190), ('A', 150), ('E', 110)]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d\n",
    "from operator import add\n",
    "rdd = sc.parallelize(dataset)\n",
    "# Select the first and last element of each tuple\n",
    "x = rdd.map(lambda rd: (rd[0], rd[3]))\n",
    "x= x.reduceByKey(add)\n",
    "x.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[(('C', 5), 190), (('E', 6), 110), (('A', 2), 70), (('A', 3), 80)]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # e\n",
    "from operator import add\n",
    "rdd = sc.parallelize(dataset)\n",
    "# Select the first,second and last element of each tuple and group by the first element and second element\n",
    "x2 = rdd.map(lambda rd: ((rd[0], rd[1]), rd[3]))\n",
    "# reduce by the first and second element\n",
    "x2 = x2.reduceByKey(add)\n",
    "x2.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 190)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f\n",
    "# Output a x[2] when the greatest number of x[3]\n",
    "rdd = sc.parallelize(dataset)\n",
    "x3 = rdd.map(lambda rd: (rd[2], rd[3]))\n",
    "x3 = x3.reduceByKey(add)\n",
    "x3.max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserId: integer (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- AllZero: integer (nullable = true)\n",
      " |-- Altitude: double (nullable = true)\n",
      " |-- Timestamp: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"UserId\", IntegerType(), True),\n",
    "    StructField(\"Latitude\", DoubleType(), True),\n",
    "    StructField(\"Longitude\", DoubleType(), True),\n",
    "    StructField(\"AllZero\", IntegerType(), True),\n",
    "    StructField(\"Altitude\", DoubleType(), True),\n",
    "    StructField(\"Timestamp\", DoubleType(), True),\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.csv('dataset.txt', header=True, schema=schema)\n",
    "# Timestamp is sufficient to re-calculate the date and time\n",
    "df = df.drop('Date', 'Time')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Time difference between Beijing and UTC\n",
    "time_diff = 8 * 3600\n",
    "# the difference between Epoch & Unix Timestamp and current time stamp base\n",
    "interval = (datetime.datetime(1970, 1, 1) - datetime.datetime(1899, 12, 30)).total_seconds()\n",
    "# change the timestamp to Unix Timestamp + 8 hours\n",
    "df = df.withColumn('Timestamp', col('Timestamp') * 24 * 3600 + time_diff - interval)\n",
    "\n",
    "to_date = udf(lambda x: datetime.datetime.fromtimestamp(x.Timestamp, datetime.timezone.utc).strftime('%Y-%m-%d'), StringType())\n",
    "to_time = udf(lambda x: datetime.datetime.fromtimestamp(x.Timestamp, datetime.timezone.utc).strftime('%H:%M:%S'), StringType())\n",
    "\n",
    "df = df.withColumn(\"Date\",to_date(struct([df[x] for x in df.columns])))\n",
    "df = df.withColumn(\"Time\",to_time(struct([df[x] for x in df.columns])))\n",
    "\n",
    "# Combine the latitude and longitude to a single column\n",
    "df = df.withColumn(\"Coordinate\",struct(df.Latitude, df.Longitude)).drop('Latitude', 'Longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------------+--------------------+----------+--------+--------------------+\n",
      "|UserId|AllZero|        Altitude|           Timestamp|      Date|    Time|          Coordinate|\n",
      "+------+-------+----------------+--------------------+----------+--------+--------------------+\n",
      "|   100|      0|480.287355643045|1.3119722519999962E9|2011-07-29|20:44:11|{39.974408918, 11...|\n",
      "|   100|      0|480.121151574803|1.3119722529999986E9|2011-07-29|20:44:12|{39.974397078, 11...|\n",
      "|   100|      0|478.499455380577|1.3119722550000029E9|2011-07-29|20:44:15|{39.973982524, 11...|\n",
      "|   100|      0|479.176988188976|1.3119722559999962E9|2011-07-29|20:44:15|{39.973943291, 11...|\n",
      "|   100|      0|479.129432414698|1.3119722569999986E9|2011-07-29|20:44:16|{39.973937148, 11...|\n",
      "+------+-------+----------------+--------------------+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate for each person, on how many days was the data recorded for them (count any day with\n",
    "at least one data point).\n",
    "'''\n",
    "date_df = df.select('UserId','Date').drop_duplicates()\n",
    "date_count = date_df.groupBy('UserID').count().sort(desc('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|UserID|count|\n",
      "+------+-----+\n",
      "|   128|  910|\n",
      "|   126|  178|\n",
      "|   104|  117|\n",
      "|   115|  116|\n",
      "|   112|  109|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "date_count.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|UserID|count|\n",
      "+------+-----+\n",
      "|   128|  873|\n",
      "|   126|  171|\n",
      "|   115|  100|\n",
      "|   112|   98|\n",
      "|   104|   86|\n",
      "|   125|   48|\n",
      "|   119|   45|\n",
      "|   101|   31|\n",
      "|   122|   24|\n",
      "|   103|   22|\n",
      "|   102|   21|\n",
      "|   130|   20|\n",
      "|   111|   20|\n",
      "|   113|   19|\n",
      "|   110|   16|\n",
      "|   114|   15|\n",
      "|   105|    8|\n",
      "|   121|    7|\n",
      "|   127|    7|\n",
      "|   124|    6|\n",
      "|   100|    5|\n",
      "|   123|    4|\n",
      "|   129|    3|\n",
      "|   106|    3|\n",
      "|   116|    3|\n",
      "|   108|    2|\n",
      "|   120|    2|\n",
      "|   109|    2|\n",
      "|   118|    2|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculate for each person, on how many days there were more than 100 data points recorded for them (count any day with at least 100 data points). Output all user IDs and the corresponding value of this measure.\n",
    "'''\n",
    "date_duplicate = df.select('UserId','Date').groupBy('UserID','Date').count().filter(col('count') >= 100)\n",
    "df_user_date = date_duplicate.select('UserId').groupBy('UserID').count().sort(desc('count'))\n",
    "df_user_date.show(df_user_date.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate for each person, the highest altitude that they reached. Output the top 5 user ID according to this measure, its value and the day that was achieved.\n",
    "'''\n",
    "windowDept = Window.partitionBy(\"UserId\").orderBy(col(\"Altitude\").desc())\n",
    "df_altitude = df.select('UserId','Altitude', 'Date')\n",
    "df_altitude = df_altitude.withColumn(\"row\",row_number().over(windowDept)).filter(col(\"row\") == 1).drop(\"row\").sort(desc('Altitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------+\n",
      "|UserId|        Altitude|      Date|\n",
      "+------+----------------+----------+\n",
      "|   128|        107503.3|2009-11-02|\n",
      "|   106|36581.3648293963|2007-10-09|\n",
      "|   103|         25259.2|2008-09-12|\n",
      "|   101|         24806.4|2008-03-28|\n",
      "|   126|         19432.4|2008-06-22|\n",
      "+------+----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_altitude.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate for each person, the timespan of the observation, i.e., the difference between the highest timestamp of his/her observation and the lowest one. Output the top 5 user ID according to this measure and its value.\n",
    "'''\n",
    "df_timestamp_extrema = df.select(\n",
    "  'UserId', 'Timestamp',\n",
    ").groupBy(\n",
    "  'UserId'\n",
    ").agg(\n",
    "  min('Timestamp').alias('Timestamp_min'),\n",
    "  max('Timestamp').alias('Timestamp_max'),\n",
    ")\n",
    "\n",
    "time_diff = udf(lambda x: x.Timestamp_max - x.Timestamp_min, DoubleType())\n",
    "df_timespan = df_timestamp_extrema.withColumn('TimeSpan', time_diff(struct([df_timestamp_extrema[x] for x in df_timestamp_extrema.columns]))).sort(desc('TimeSpan'))\n",
    "df_timespan = df_timespan.drop('Timestamp_min', 'Timestamp_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|UserId|            TimeSpan|\n",
      "+------+--------------------+\n",
      "|   128|        1.23231834E8|\n",
      "|   114| 8.327625900000238E7|\n",
      "|   111|          7.247087E7|\n",
      "|   115| 4.377784700000143E7|\n",
      "|   126|2.8151853999998093E7|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_timespan.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate for each person, the distance travelled by them each day. For each user output the (earliest) day they travelled the most. Also, output the total distance travelled by all users on all days.\n",
    "'''\n",
    "df_distance = df.select('UserId','Coordinate','Date', 'Timestamp')\n",
    "# calculate the distance between two points\n",
    "def get_distance_between_two_points(row):\n",
    "    coord1 = row.Coordinate\n",
    "    coord2 = row.lag_Coordinate\n",
    "    if coord1 is None or coord2 is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return  geopy.distance.geodesic(coord1, coord2).km\n",
    "\n",
    "# lag the coordinate column\n",
    "same_day_window = Window.partitionBy(\"UserID\", \"Date\").orderBy(\"Timestamp\")\n",
    "df_distance = df_distance.withColumn('lag_Coordinate', lag(df_distance['Coordinate']).over(same_day_window))\n",
    "\n",
    "distance_udf = udf(get_distance_between_two_points, DoubleType())\n",
    "# calculate the distance travelled by each user each coordinate change\n",
    "df_distance = df_distance.withColumn('DistanceByCoordinate', distance_udf(struct([df_distance[x] for x in df_distance.columns])))\n",
    "# calculate the total distance travelled by each user each day\n",
    "df_distance_agg = df_distance.groupBy('UserID', 'Date').sum('DistanceByCoordinate').sort(desc('sum(DistanceByCoordinate)')).withColumnRenamed('sum(DistanceByCoordinate)', \"DistanceByDay\")\n",
    "\n",
    "# calculate the max daily distance travelled by each user\n",
    "distance_user_window = Window.partitionBy(\"UserID\").orderBy(col('DistanceByDay').desc())\n",
    "df_distance_user = df_distance_agg.select('UserId','DistanceByDay','Date').withColumn(\"row\",row_number().over(distance_user_window)).filter(col(\"row\") == 1).drop(\"row\").sort(desc('DistanceByDay'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6\n"
     ]
    }
   ],
   "source": [
    "print('Step 6')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+----------+\n",
      "|UserId|     DistanceByDay|      Date|\n",
      "+------+------------------+----------+\n",
      "|   100|12.173128258276241|2011-08-09|\n",
      "|   101|228.45342441436495|2007-12-23|\n",
      "|   102|29.849437524843076|2011-12-31|\n",
      "|   103|194.34882725105257|2008-09-12|\n",
      "|   104|112.41388625202974|2008-09-11|\n",
      "|   105| 58.97419690548178|2007-10-06|\n",
      "|   106|252.92611172528123|2007-10-09|\n",
      "|   107| 8.570857323698148|2007-10-07|\n",
      "|   108|165.43560669850862|2007-10-04|\n",
      "|   109|35.484262239303455|2007-12-01|\n",
      "|   110| 89.48598039196608|2008-01-19|\n",
      "|   111|2459.9727492396887|2007-09-05|\n",
      "|   112|118.84986296601792|2008-07-01|\n",
      "|   113|37.250444802782006|2010-06-03|\n",
      "|   114| 43.13695902871845|2010-05-29|\n",
      "|   115| 851.9804449907956|2008-09-13|\n",
      "|   116|3.3736070308458106|2011-08-03|\n",
      "|   117|15.522764119627311|2007-06-29|\n",
      "|   118| 395.8065623103833|2007-05-20|\n",
      "|   119|139.38895930121691|2008-08-29|\n",
      "|   120| 436.0508695845096|2009-09-19|\n",
      "|   121|129.46860882496455|2009-10-09|\n",
      "|   122|157.78189802778914|2009-09-02|\n",
      "|   123| 930.1983967491146|2009-09-23|\n",
      "|   124|3359.2041134607907|2008-10-03|\n",
      "|   125|1256.5061507927285|2008-08-28|\n",
      "|   126| 358.1286495772979|2008-05-01|\n",
      "|   127| 482.0850796309421|2008-09-29|\n",
      "|   128| 7329.951925073333|2009-02-22|\n",
      "|   129| 319.0229524632626|2008-05-02|\n",
      "|   130| 64.14010477253703|2009-09-12|\n",
      "+------+------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_distance_user.sort('UserId').show(df_distance_user.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 94:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|sum(DistanceByCoordinate)|\n",
      "+-------------------------+\n",
      "|         136320.404922086|\n",
      "+-------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# sum the total distance travelled by all users\n",
    "df_distance.select('DistanceByCoordinate').groupBy().sum('DistanceByCoordinate').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|sum(DistanceByDay)|\n",
      "+------------------+\n",
      "|136320.40492208552|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_distance_agg.select('DistanceByDay').groupBy().sum('DistanceByDay').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}